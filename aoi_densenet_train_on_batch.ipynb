{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "aoi_densenet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/tcglarry/aoi/blob/master/aoi_densenet_train_on_batch.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "-VVqSDpUKamG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JP-J92Wh3977",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2278
        },
        "outputId": "69517eea-678f-47be-8a17-312cb92d0683"
      },
      "cell_type": "code",
      "source": [
        "# Install a Drive FUSE wrapper.\n",
        "# https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package cron.\n",
            "(Reading database ... 18408 files and directories currently installed.)\n",
            "Preparing to unpack .../00-cron_3.0pl1-128ubuntu5_amd64.deb ...\n",
            "Unpacking cron (3.0pl1-128ubuntu5) ...\n",
            "Selecting previously unselected package libapparmor1:amd64.\n",
            "Preparing to unpack .../01-libapparmor1_2.11.0-2ubuntu17.1_amd64.deb ...\n",
            "Unpacking libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n",
            "Selecting previously unselected package libdbus-1-3:amd64.\n",
            "Preparing to unpack .../02-libdbus-1-3_1.10.22-1ubuntu1_amd64.deb ...\n",
            "Unpacking libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n",
            "Selecting previously unselected package dbus.\n",
            "Preparing to unpack .../03-dbus_1.10.22-1ubuntu1_amd64.deb ...\n",
            "Unpacking dbus (1.10.22-1ubuntu1) ...\n",
            "Selecting previously unselected package dirmngr.\n",
            "Preparing to unpack .../04-dirmngr_2.1.15-1ubuntu8.1_amd64.deb ...\n",
            "Unpacking dirmngr (2.1.15-1ubuntu8.1) ...\n",
            "Selecting previously unselected package distro-info-data.\n",
            "Preparing to unpack .../05-distro-info-data_0.36ubuntu0.2_all.deb ...\n",
            "Unpacking distro-info-data (0.36ubuntu0.2) ...\n",
            "Selecting previously unselected package libkmod2:amd64.\n",
            "Preparing to unpack .../06-libkmod2_24-1ubuntu2_amd64.deb ...\n",
            "Unpacking libkmod2:amd64 (24-1ubuntu2) ...\n",
            "Selecting previously unselected package kmod.\n",
            "Preparing to unpack .../07-kmod_24-1ubuntu2_amd64.deb ...\n",
            "Unpacking kmod (24-1ubuntu2) ...\n",
            "Selecting previously unselected package lsb-release.\n",
            "Preparing to unpack .../08-lsb-release_9.20160110ubuntu5_all.deb ...\n",
            "Unpacking lsb-release (9.20160110ubuntu5) ...\n",
            "Selecting previously unselected package libgirepository-1.0-1:amd64.\n",
            "Preparing to unpack .../09-libgirepository-1.0-1_1.54.1-1_amd64.deb ...\n",
            "Unpacking libgirepository-1.0-1:amd64 (1.54.1-1) ...\n",
            "Selecting previously unselected package gir1.2-glib-2.0:amd64.\n",
            "Preparing to unpack .../10-gir1.2-glib-2.0_1.54.1-1_amd64.deb ...\n",
            "Unpacking gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n",
            "Selecting previously unselected package iso-codes.\n",
            "Preparing to unpack .../11-iso-codes_3.75-1_all.deb ...\n",
            "Unpacking iso-codes (3.75-1) ...\n",
            "Selecting previously unselected package libdbus-glib-1-2:amd64.\n",
            "Preparing to unpack .../12-libdbus-glib-1-2_0.108-2_amd64.deb ...\n",
            "Unpacking libdbus-glib-1-2:amd64 (0.108-2) ...\n",
            "Selecting previously unselected package python-apt-common.\n",
            "Preparing to unpack .../13-python-apt-common_1.4.0~beta3build2_all.deb ...\n",
            "Unpacking python-apt-common (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python3-apt.\n",
            "Preparing to unpack .../14-python3-apt_1.4.0~beta3build2_amd64.deb ...\n",
            "Unpacking python3-apt (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python3-dbus.\n",
            "Preparing to unpack .../15-python3-dbus_1.2.4-1build3_amd64.deb ...\n",
            "Unpacking python3-dbus (1.2.4-1build3) ...\n",
            "Selecting previously unselected package python3-gi.\n",
            "Preparing to unpack .../16-python3-gi_3.24.1-2build1_amd64.deb ...\n",
            "Unpacking python3-gi (3.24.1-2build1) ...\n",
            "Selecting previously unselected package module-init-tools.\n",
            "Preparing to unpack .../17-module-init-tools_24-1ubuntu2_all.deb ...\n",
            "Unpacking module-init-tools (24-1ubuntu2) ...\n",
            "Selecting previously unselected package python-apt.\n",
            "Preparing to unpack .../18-python-apt_1.4.0~beta3build2_amd64.deb ...\n",
            "Unpacking python-apt (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python-pycurl.\n",
            "Preparing to unpack .../19-python-pycurl_7.43.0-2build2_amd64.deb ...\n",
            "Unpacking python-pycurl (7.43.0-2build2) ...\n",
            "Selecting previously unselected package python-software-properties.\n",
            "Preparing to unpack .../20-python-software-properties_0.96.24.17_all.deb ...\n",
            "Unpacking python-software-properties (0.96.24.17) ...\n",
            "Selecting previously unselected package python3-software-properties.\n",
            "Preparing to unpack .../21-python3-software-properties_0.96.24.17_all.deb ...\n",
            "Unpacking python3-software-properties (0.96.24.17) ...\n",
            "Selecting previously unselected package software-properties-common.\n",
            "Preparing to unpack .../22-software-properties-common_0.96.24.17_all.deb ...\n",
            "Unpacking software-properties-common (0.96.24.17) ...\n",
            "Selecting previously unselected package unattended-upgrades.\n",
            "Preparing to unpack .../23-unattended-upgrades_0.98ubuntu1.1_all.deb ...\n",
            "Unpacking unattended-upgrades (0.98ubuntu1.1) ...\n",
            "Setting up python-apt-common (1.4.0~beta3build2) ...\n",
            "Setting up python3-apt (1.4.0~beta3build2) ...\n",
            "Setting up iso-codes (3.75-1) ...\n",
            "Setting up distro-info-data (0.36ubuntu0.2) ...\n",
            "Setting up python-pycurl (7.43.0-2build2) ...\n",
            "Setting up lsb-release (9.20160110ubuntu5) ...\n",
            "Setting up libgirepository-1.0-1:amd64 (1.54.1-1) ...\n",
            "Setting up libkmod2:amd64 (24-1ubuntu2) ...\n",
            "Setting up gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n",
            "Setting up unattended-upgrades (0.98ubuntu1.1) ...\n",
            "\n",
            "Creating config file /etc/apt/apt.conf.d/20auto-upgrades with new version\n",
            "\n",
            "Creating config file /etc/apt/apt.conf.d/50unattended-upgrades with new version\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up dirmngr (2.1.15-1ubuntu8.1) ...\n",
            "Setting up cron (3.0pl1-128ubuntu5) ...\n",
            "Adding group `crontab' (GID 102) ...\n",
            "Done.\n",
            "update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults\n",
            "update-rc.d: warning: stop runlevel arguments (1) do not match cron Default-Stop values (none)\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n",
            "Setting up kmod (24-1ubuntu2) ...\n",
            "Setting up libdbus-glib-1-2:amd64 (0.108-2) ...\n",
            "Setting up python3-gi (3.24.1-2build1) ...\n",
            "Setting up module-init-tools (24-1ubuntu2) ...\n",
            "Setting up python3-software-properties (0.96.24.17) ...\n",
            "Setting up dbus (1.10.22-1ubuntu1) ...\n",
            "Setting up python-apt (1.4.0~beta3build2) ...\n",
            "Setting up python3-dbus (1.2.4-1build3) ...\n",
            "Setting up python-software-properties (0.96.24.17) ...\n",
            "Setting up software-properties-common (0.96.24.17) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Processing triggers for dbus (1.10.22-1ubuntu1) ...\n",
            "gpg: keybox '/tmp/tmp8debcis_/pubring.gpg' created\n",
            "gpg: /tmp/tmp8debcis_/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "Selecting previously unselected package libfuse2:amd64.\n",
            "(Reading database ... 19816 files and directories currently installed.)\n",
            "Preparing to unpack .../libfuse2_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package fuse.\n",
            "Preparing to unpack .../fuse_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking fuse (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.6.21-0ubuntu2_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n",
            "Setting up libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up fuse (2.9.7-1ubuntu1) ...\n",
            "Setting up google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L3uvWPGk3-RR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generate auth tokens for Colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r7BNchFr3-jM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "cb79d0a1-4f39-4dbb-9311-0d7cbb7b711b"
      },
      "cell_type": "code",
      "source": [
        "# Generate creds for the Drive FUSE library.\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UacDwvvo3-3M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ef8090c5-f09f-44db-97f5-97c186d0b972"
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "!ls drive"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aoi_aoi_test1.ipynb  Sample upload.txt\t\t\t      Untitled1.ipynb\r\n",
            "aoi_test\t     TAHU PowerPoint Template.pdf\t      Untitled2.ipynb\r\n",
            "Capstone_PixNet.zip  TAHU PowerPoint Template - 柱狀圖 1.ods  Untitled3.ipynb\r\n",
            "Colab Notebooks      test for excel\r\n",
            "PiXNet\t\t     Untitled0.ipynb\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1RFtPLNO32Fc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "753578c3-20b4-41e2-ca93-01cdb41b8b56"
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.densenet import DenseNet121\n",
        "from keras.preprocessing import image\n",
        "\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "import subprocess\n",
        "import os\n",
        "import pickle\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, merge, Lambda,UpSampling2D, concatenate, Reshape\n",
        "from keras.models import Model, load_model\n",
        "import pandas as pd\n",
        "import sklearn \n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import Callback"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "JrKfEZEq3wpf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eSJ7LqCJMATT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "src = 'drive/aoi_test/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kIpukFWkKamQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "29ca31a6-9437-4ba4-f01e-5cf537301877"
      },
      "cell_type": "code",
      "source": [
        "train_img = os.listdir(src+'train_images')\n",
        "print ('iamge lies size', len(train_img))\n",
        "img_list=[]\n",
        "for i,img in enumerate(train_img):\n",
        "    x = cv2.imread(src+'train_images/'+img)\n",
        "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
        "    #x = x/127.5 -1.\n",
        "    img_list.append(x)\n",
        "    \n",
        "print ('done')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iamge lies size 2528\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "13PLIoefUD1T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qcYVau44KamW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "87e98c3f-ac53-4ec9-9419-291c523a74b0"
      },
      "cell_type": "code",
      "source": [
        "train_data = np.array(img_list)\n",
        "print (train_data.shape)\n",
        "#train_data =  train_data[:,:,:,np.newaxis]\n",
        "print (train_data.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2528, 512, 512, 3)\n",
            "(2528, 512, 512, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JTk9WdC-WuQM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c71ccba1-beb2-4bce-cf56-41741d6eb3af"
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "with open(src+'train_data.pickle', 'wb') as handle:\n",
        "    pickle.dump(train_data, handle)\n",
        "'''"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nwith open(src+'train_data.pickle', 'wb') as handle:\\n    pickle.dump(train_data, handle)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "3HFXvsHaMas5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba83ced0-a9c3-4521-c8cb-8abd7e5e1c7e"
      },
      "cell_type": "code",
      "source": [
        "print ('here')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "here\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dColgcfbKamb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "67fb55ec-3d65-463f-958d-5395c8d0b6f5"
      },
      "cell_type": "code",
      "source": [
        "df_y = pd.read_csv(src+'train.csv')\n",
        "print (df_y['Label'].value_counts())\n",
        "train_y =  df_y['Label'].values\n",
        "\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "train_y = train_y.reshape(len(train_y), 1)\n",
        "print (train_y.shape)\n",
        "train_label = onehot_encoder.fit_transform(train_y)\n",
        "\n",
        "\n",
        "print ('beofre', train_label.shape)\n",
        "print (df_y['Label'][:10])\n",
        "print (train_label[:10,:])\n",
        "\n",
        "train_label = train_label[:,np.newaxis,np.newaxis,:]\n",
        "\n",
        "print ('after', train_label.shape)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    674\n",
            "5    644\n",
            "1    492\n",
            "3    378\n",
            "4    240\n",
            "2    100\n",
            "Name: Label, dtype: int64\n",
            "(2528, 1)\n",
            "beofre (2528, 6)\n",
            "0    0\n",
            "1    1\n",
            "2    1\n",
            "3    5\n",
            "4    5\n",
            "5    5\n",
            "6    3\n",
            "7    0\n",
            "8    3\n",
            "9    5\n",
            "Name: Label, dtype: int64\n",
            "[[1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]]\n",
            "after (2528, 1, 1, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rm6urMyINOKV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CollectOutputAndTarget(Callback):\n",
        "    def __init__(self):\n",
        "        super(CollectOutputAndTarget, self).__init__()\n",
        "        self.targets = []  # collect y_true batches\n",
        "        self.outputs = []  # collect y_pred batches\n",
        "\n",
        "        # the shape of these 2 variables will change according to batch shape\n",
        "        # to handle the \"last batch\", specify `validate_shape=False`\n",
        "        self.var_y_true = tf.Variable(0., validate_shape=False)\n",
        "        self.var_y_pred = tf.Variable(0., validate_shape=False)\n",
        "\n",
        "    def on_epoch_end(self, batch, logs=None):\n",
        "        # evaluate the variables and save them into lists\n",
        "        '''\n",
        "        print ('\\n 0', len(self.validation_data))\n",
        "        print ('1',  self.validation_data[0].shape )\n",
        "        print ('2',  self.validation_data[1].shape )\n",
        "        print ( '3', self.validation_data[2].shape )\n",
        "        \n",
        "        print ('4', test.shape)\n",
        "       \n",
        "        print ('5', test2.shape)\n",
        "        \n",
        "        print ('6', test3.shape)\n",
        "        '''\n",
        "        test = self.model.predict(self.validation_data[0])\n",
        "        test2 = np.squeeze(test)\n",
        "        test3 = np.argmax(test2,axis=1)\n",
        "        print ('y_pred = \\n', test3[:30])\n",
        "        test_4 = np.squeeze(self.validation_data[1])\n",
        "        test_5 = np.argmax(test_4,axis=1)\n",
        "        print ('y_true = \\n', test_5[:30])\n",
        "        \n",
        "        #print ('6', np.argmax(np.squeeze(test),axis=1))\n",
        "        #out_result = np.argmax(np.squeeze(self.model.predict(self.validation_data[0])),axis=1)\n",
        "        #ground_truth = np.argmax(np.squeeze (self.validation_data[1]), axis=1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4u4e5RX8Kamg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d80c95e4-55a6-45dd-a30f-c0d90fadf0a6"
      },
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(512,512,3))\n",
        "inputs = Lambda(lambda x: x/275. - 1.0)(inputs)\n",
        "# create the base pre-trained model\n",
        "base_model = DenseNet121(weights='imagenet',input_tensor=inputs, input_shape=(512,512,3), include_top=False)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.8/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "30015488/30011760 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Bdfp0NoXKaml",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "63292510-95cb-4fc4-f965-8eeaf6798f16"
      },
      "cell_type": "code",
      "source": [
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "print ('shape of densenet output', x.get_shape())\n",
        "#x = MaxPooling2D(pool_size=(2,2))(x)\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "print ('shape of pooling output', x.get_shape())\n",
        "# let's add a fully-connected layer\n",
        "#x = Conv2D(32,(5,5), activation='relu', padding='valid')(x)\n",
        "#x = Conv2D(128,(3,3), activation='relu', padding='valid')(x)\n",
        "#x = Conv2D(128,(2,2), activation='relu', padding='valid')(x)\n",
        "#predictions = Conv2D(6,(1,1), activation='relu', padding='same')(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "# and a logistic layer -- let's say we have 200 classes\n",
        "predictions = Dense(6, activation='softmax')(x)\n",
        "predictions = Reshape(target_shape=(1,1,6))(predictions)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of densenet output (?, 16, 16, 1024)\n",
            "shape of pooling output (?, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DiJtsombKamq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 15776
        },
        "outputId": "65a060bf-025f-4b7f-f90a-74cc4b8beb97"
      },
      "cell_type": "code",
      "source": [
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 512, 512, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 518, 518, 3)  0           lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1/conv (Conv2D)             (None, 256, 256, 64) 9408        zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv1/bn (BatchNormalization)   (None, 256, 256, 64) 256         conv1/conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1/relu (Activation)         (None, 256, 256, 64) 0           conv1/bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, 258, 258, 64) 0           conv1/relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (MaxPooling2D)            (None, 128, 128, 64) 0           zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 128, 128, 64) 256         pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_relu (Activation (None, 128, 128, 64) 0           conv2_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 128, 128, 128 8192        conv2_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 128, 128, 128 512         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 128, 128, 128 0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 128, 128, 32) 36864       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_concat (Concatenat (None, 128, 128, 96) 0           pool1[0][0]                      \n",
            "                                                                 conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_bn (BatchNormali (None, 128, 128, 96) 384         conv2_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_relu (Activation (None, 128, 128, 96) 0           conv2_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 128, 128, 128 12288       conv2_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 128, 128, 128 512         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 128, 128, 128 0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 128, 128, 32) 36864       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_concat (Concatenat (None, 128, 128, 128 0           conv2_block1_concat[0][0]        \n",
            "                                                                 conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_bn (BatchNormali (None, 128, 128, 128 512         conv2_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_relu (Activation (None, 128, 128, 128 0           conv2_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 128, 128, 128 16384       conv2_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 128, 128, 128 512         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 128, 128, 128 0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 128, 128, 32) 36864       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_concat (Concatenat (None, 128, 128, 160 0           conv2_block2_concat[0][0]        \n",
            "                                                                 conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_bn (BatchNormali (None, 128, 128, 160 640         conv2_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_relu (Activation (None, 128, 128, 160 0           conv2_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_conv (Conv2D)    (None, 128, 128, 128 20480       conv2_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_bn (BatchNormali (None, 128, 128, 128 512         conv2_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_relu (Activation (None, 128, 128, 128 0           conv2_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_2_conv (Conv2D)    (None, 128, 128, 32) 36864       conv2_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_concat (Concatenat (None, 128, 128, 192 0           conv2_block3_concat[0][0]        \n",
            "                                                                 conv2_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_bn (BatchNormali (None, 128, 128, 192 768         conv2_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_relu (Activation (None, 128, 128, 192 0           conv2_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_conv (Conv2D)    (None, 128, 128, 128 24576       conv2_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_bn (BatchNormali (None, 128, 128, 128 512         conv2_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_relu (Activation (None, 128, 128, 128 0           conv2_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_2_conv (Conv2D)    (None, 128, 128, 32) 36864       conv2_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_concat (Concatenat (None, 128, 128, 224 0           conv2_block4_concat[0][0]        \n",
            "                                                                 conv2_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_bn (BatchNormali (None, 128, 128, 224 896         conv2_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_relu (Activation (None, 128, 128, 224 0           conv2_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_conv (Conv2D)    (None, 128, 128, 128 28672       conv2_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_bn (BatchNormali (None, 128, 128, 128 512         conv2_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_relu (Activation (None, 128, 128, 128 0           conv2_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_2_conv (Conv2D)    (None, 128, 128, 32) 36864       conv2_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_concat (Concatenat (None, 128, 128, 256 0           conv2_block5_concat[0][0]        \n",
            "                                                                 conv2_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_bn (BatchNormalization)   (None, 128, 128, 256 1024        conv2_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_relu (Activation)         (None, 128, 128, 256 0           pool2_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool2_conv (Conv2D)             (None, 128, 128, 128 32768       pool2_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool2_pool (AveragePooling2D)   (None, 64, 64, 128)  0           pool2_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 64, 64, 128)  512         pool2_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_relu (Activation (None, 64, 64, 128)  0           conv3_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 64, 64, 128)  16384       conv3_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 64, 64, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_concat (Concatenat (None, 64, 64, 160)  0           pool2_pool[0][0]                 \n",
            "                                                                 conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_bn (BatchNormali (None, 64, 64, 160)  640         conv3_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_relu (Activation (None, 64, 64, 160)  0           conv3_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 64, 64, 128)  20480       conv3_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 64, 64, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_concat (Concatenat (None, 64, 64, 192)  0           conv3_block1_concat[0][0]        \n",
            "                                                                 conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_bn (BatchNormali (None, 64, 64, 192)  768         conv3_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_relu (Activation (None, 64, 64, 192)  0           conv3_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 64, 64, 128)  24576       conv3_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 64, 64, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_concat (Concatenat (None, 64, 64, 224)  0           conv3_block2_concat[0][0]        \n",
            "                                                                 conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_bn (BatchNormali (None, 64, 64, 224)  896         conv3_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_relu (Activation (None, 64, 64, 224)  0           conv3_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 64, 64, 128)  28672       conv3_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 64, 64, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_concat (Concatenat (None, 64, 64, 256)  0           conv3_block3_concat[0][0]        \n",
            "                                                                 conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv3_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_relu (Activation (None, 64, 64, 256)  0           conv3_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_conv (Conv2D)    (None, 64, 64, 128)  32768       conv3_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_relu (Activation (None, 64, 64, 128)  0           conv3_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv3_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_concat (Concatenat (None, 64, 64, 288)  0           conv3_block4_concat[0][0]        \n",
            "                                                                 conv3_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_bn (BatchNormali (None, 64, 64, 288)  1152        conv3_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_relu (Activation (None, 64, 64, 288)  0           conv3_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_conv (Conv2D)    (None, 64, 64, 128)  36864       conv3_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_relu (Activation (None, 64, 64, 128)  0           conv3_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv3_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_concat (Concatenat (None, 64, 64, 320)  0           conv3_block5_concat[0][0]        \n",
            "                                                                 conv3_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_bn (BatchNormali (None, 64, 64, 320)  1280        conv3_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_relu (Activation (None, 64, 64, 320)  0           conv3_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_conv (Conv2D)    (None, 64, 64, 128)  40960       conv3_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_relu (Activation (None, 64, 64, 128)  0           conv3_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv3_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_concat (Concatenat (None, 64, 64, 352)  0           conv3_block6_concat[0][0]        \n",
            "                                                                 conv3_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_bn (BatchNormali (None, 64, 64, 352)  1408        conv3_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_relu (Activation (None, 64, 64, 352)  0           conv3_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_conv (Conv2D)    (None, 64, 64, 128)  45056       conv3_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_relu (Activation (None, 64, 64, 128)  0           conv3_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv3_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_concat (Concatenat (None, 64, 64, 384)  0           conv3_block7_concat[0][0]        \n",
            "                                                                 conv3_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_bn (BatchNormali (None, 64, 64, 384)  1536        conv3_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_relu (Activation (None, 64, 64, 384)  0           conv3_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_conv (Conv2D)    (None, 64, 64, 128)  49152       conv3_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_relu (Activation (None, 64, 64, 128)  0           conv3_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv3_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_concat (Concatenat (None, 64, 64, 416)  0           conv3_block8_concat[0][0]        \n",
            "                                                                 conv3_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_bn (BatchNormal (None, 64, 64, 416)  1664        conv3_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_relu (Activatio (None, 64, 64, 416)  0           conv3_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_conv (Conv2D)   (None, 64, 64, 128)  53248       conv3_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_bn (BatchNormal (None, 64, 64, 128)  512         conv3_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_relu (Activatio (None, 64, 64, 128)  0           conv3_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_2_conv (Conv2D)   (None, 64, 64, 32)   36864       conv3_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_concat (Concatena (None, 64, 64, 448)  0           conv3_block9_concat[0][0]        \n",
            "                                                                 conv3_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_bn (BatchNormal (None, 64, 64, 448)  1792        conv3_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_relu (Activatio (None, 64, 64, 448)  0           conv3_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_conv (Conv2D)   (None, 64, 64, 128)  57344       conv3_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_bn (BatchNormal (None, 64, 64, 128)  512         conv3_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_relu (Activatio (None, 64, 64, 128)  0           conv3_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_2_conv (Conv2D)   (None, 64, 64, 32)   36864       conv3_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_concat (Concatena (None, 64, 64, 480)  0           conv3_block10_concat[0][0]       \n",
            "                                                                 conv3_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_bn (BatchNormal (None, 64, 64, 480)  1920        conv3_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_relu (Activatio (None, 64, 64, 480)  0           conv3_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_conv (Conv2D)   (None, 64, 64, 128)  61440       conv3_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_bn (BatchNormal (None, 64, 64, 128)  512         conv3_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_relu (Activatio (None, 64, 64, 128)  0           conv3_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_2_conv (Conv2D)   (None, 64, 64, 32)   36864       conv3_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_concat (Concatena (None, 64, 64, 512)  0           conv3_block11_concat[0][0]       \n",
            "                                                                 conv3_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_bn (BatchNormalization)   (None, 64, 64, 512)  2048        conv3_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_relu (Activation)         (None, 64, 64, 512)  0           pool3_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool3_conv (Conv2D)             (None, 64, 64, 256)  131072      pool3_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool3_pool (AveragePooling2D)   (None, 32, 32, 256)  0           pool3_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 32, 32, 256)  1024        pool3_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_relu (Activation (None, 32, 32, 256)  0           conv4_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32768       conv4_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 32, 32, 128)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_concat (Concatenat (None, 32, 32, 288)  0           pool3_pool[0][0]                 \n",
            "                                                                 conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_bn (BatchNormali (None, 32, 32, 288)  1152        conv4_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_relu (Activation (None, 32, 32, 288)  0           conv4_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 32, 32, 128)  36864       conv4_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 32, 32, 128)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_concat (Concatenat (None, 32, 32, 320)  0           conv4_block1_concat[0][0]        \n",
            "                                                                 conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_bn (BatchNormali (None, 32, 32, 320)  1280        conv4_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_relu (Activation (None, 32, 32, 320)  0           conv4_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 32, 32, 128)  40960       conv4_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 32, 32, 128)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_concat (Concatenat (None, 32, 32, 352)  0           conv4_block2_concat[0][0]        \n",
            "                                                                 conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_bn (BatchNormali (None, 32, 32, 352)  1408        conv4_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_relu (Activation (None, 32, 32, 352)  0           conv4_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 32, 32, 128)  45056       conv4_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 32, 32, 128)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_concat (Concatenat (None, 32, 32, 384)  0           conv4_block3_concat[0][0]        \n",
            "                                                                 conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_bn (BatchNormali (None, 32, 32, 384)  1536        conv4_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_relu (Activation (None, 32, 32, 384)  0           conv4_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 32, 32, 128)  49152       conv4_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 32, 32, 128)  512         conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 32, 32, 128)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_concat (Concatenat (None, 32, 32, 416)  0           conv4_block4_concat[0][0]        \n",
            "                                                                 conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_bn (BatchNormali (None, 32, 32, 416)  1664        conv4_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_relu (Activation (None, 32, 32, 416)  0           conv4_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 32, 32, 128)  53248       conv4_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 32, 32, 128)  512         conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 32, 32, 128)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_concat (Concatenat (None, 32, 32, 448)  0           conv4_block5_concat[0][0]        \n",
            "                                                                 conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_bn (BatchNormali (None, 32, 32, 448)  1792        conv4_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_relu (Activation (None, 32, 32, 448)  0           conv4_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_conv (Conv2D)    (None, 32, 32, 128)  57344       conv4_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_bn (BatchNormali (None, 32, 32, 128)  512         conv4_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_relu (Activation (None, 32, 32, 128)  0           conv4_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv4_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_concat (Concatenat (None, 32, 32, 480)  0           conv4_block6_concat[0][0]        \n",
            "                                                                 conv4_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_bn (BatchNormali (None, 32, 32, 480)  1920        conv4_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_relu (Activation (None, 32, 32, 480)  0           conv4_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_conv (Conv2D)    (None, 32, 32, 128)  61440       conv4_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_bn (BatchNormali (None, 32, 32, 128)  512         conv4_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_relu (Activation (None, 32, 32, 128)  0           conv4_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv4_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_concat (Concatenat (None, 32, 32, 512)  0           conv4_block7_concat[0][0]        \n",
            "                                                                 conv4_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv4_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_relu (Activation (None, 32, 32, 512)  0           conv4_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv4_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_bn (BatchNormali (None, 32, 32, 128)  512         conv4_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_relu (Activation (None, 32, 32, 128)  0           conv4_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv4_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_concat (Concatenat (None, 32, 32, 544)  0           conv4_block8_concat[0][0]        \n",
            "                                                                 conv4_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_bn (BatchNormal (None, 32, 32, 544)  2176        conv4_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_relu (Activatio (None, 32, 32, 544)  0           conv4_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_conv (Conv2D)   (None, 32, 32, 128)  69632       conv4_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_concat (Concatena (None, 32, 32, 576)  0           conv4_block9_concat[0][0]        \n",
            "                                                                 conv4_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_bn (BatchNormal (None, 32, 32, 576)  2304        conv4_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_relu (Activatio (None, 32, 32, 576)  0           conv4_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_conv (Conv2D)   (None, 32, 32, 128)  73728       conv4_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_concat (Concatena (None, 32, 32, 608)  0           conv4_block10_concat[0][0]       \n",
            "                                                                 conv4_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_bn (BatchNormal (None, 32, 32, 608)  2432        conv4_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_relu (Activatio (None, 32, 32, 608)  0           conv4_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_conv (Conv2D)   (None, 32, 32, 128)  77824       conv4_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_concat (Concatena (None, 32, 32, 640)  0           conv4_block11_concat[0][0]       \n",
            "                                                                 conv4_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_bn (BatchNormal (None, 32, 32, 640)  2560        conv4_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_relu (Activatio (None, 32, 32, 640)  0           conv4_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_conv (Conv2D)   (None, 32, 32, 128)  81920       conv4_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_concat (Concatena (None, 32, 32, 672)  0           conv4_block12_concat[0][0]       \n",
            "                                                                 conv4_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_bn (BatchNormal (None, 32, 32, 672)  2688        conv4_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_relu (Activatio (None, 32, 32, 672)  0           conv4_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_conv (Conv2D)   (None, 32, 32, 128)  86016       conv4_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_concat (Concatena (None, 32, 32, 704)  0           conv4_block13_concat[0][0]       \n",
            "                                                                 conv4_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_bn (BatchNormal (None, 32, 32, 704)  2816        conv4_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_relu (Activatio (None, 32, 32, 704)  0           conv4_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_conv (Conv2D)   (None, 32, 32, 128)  90112       conv4_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_concat (Concatena (None, 32, 32, 736)  0           conv4_block14_concat[0][0]       \n",
            "                                                                 conv4_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_bn (BatchNormal (None, 32, 32, 736)  2944        conv4_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_relu (Activatio (None, 32, 32, 736)  0           conv4_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_conv (Conv2D)   (None, 32, 32, 128)  94208       conv4_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_concat (Concatena (None, 32, 32, 768)  0           conv4_block15_concat[0][0]       \n",
            "                                                                 conv4_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_bn (BatchNormal (None, 32, 32, 768)  3072        conv4_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_relu (Activatio (None, 32, 32, 768)  0           conv4_block17_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_conv (Conv2D)   (None, 32, 32, 128)  98304       conv4_block17_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block17_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block17_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block17_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_concat (Concatena (None, 32, 32, 800)  0           conv4_block16_concat[0][0]       \n",
            "                                                                 conv4_block17_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_bn (BatchNormal (None, 32, 32, 800)  3200        conv4_block17_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_relu (Activatio (None, 32, 32, 800)  0           conv4_block18_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_conv (Conv2D)   (None, 32, 32, 128)  102400      conv4_block18_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block18_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block18_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block18_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_concat (Concatena (None, 32, 32, 832)  0           conv4_block17_concat[0][0]       \n",
            "                                                                 conv4_block18_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_bn (BatchNormal (None, 32, 32, 832)  3328        conv4_block18_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_relu (Activatio (None, 32, 32, 832)  0           conv4_block19_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_conv (Conv2D)   (None, 32, 32, 128)  106496      conv4_block19_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block19_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block19_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block19_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_concat (Concatena (None, 32, 32, 864)  0           conv4_block18_concat[0][0]       \n",
            "                                                                 conv4_block19_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_bn (BatchNormal (None, 32, 32, 864)  3456        conv4_block19_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_relu (Activatio (None, 32, 32, 864)  0           conv4_block20_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_conv (Conv2D)   (None, 32, 32, 128)  110592      conv4_block20_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block20_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block20_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block20_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_concat (Concatena (None, 32, 32, 896)  0           conv4_block19_concat[0][0]       \n",
            "                                                                 conv4_block20_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_bn (BatchNormal (None, 32, 32, 896)  3584        conv4_block20_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_relu (Activatio (None, 32, 32, 896)  0           conv4_block21_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_conv (Conv2D)   (None, 32, 32, 128)  114688      conv4_block21_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block21_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block21_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block21_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_concat (Concatena (None, 32, 32, 928)  0           conv4_block20_concat[0][0]       \n",
            "                                                                 conv4_block21_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_bn (BatchNormal (None, 32, 32, 928)  3712        conv4_block21_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_relu (Activatio (None, 32, 32, 928)  0           conv4_block22_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_conv (Conv2D)   (None, 32, 32, 128)  118784      conv4_block22_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block22_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block22_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block22_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_concat (Concatena (None, 32, 32, 960)  0           conv4_block21_concat[0][0]       \n",
            "                                                                 conv4_block22_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_bn (BatchNormal (None, 32, 32, 960)  3840        conv4_block22_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_relu (Activatio (None, 32, 32, 960)  0           conv4_block23_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_conv (Conv2D)   (None, 32, 32, 128)  122880      conv4_block23_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block23_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block23_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block23_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_concat (Concatena (None, 32, 32, 992)  0           conv4_block22_concat[0][0]       \n",
            "                                                                 conv4_block23_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_bn (BatchNormal (None, 32, 32, 992)  3968        conv4_block23_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_relu (Activatio (None, 32, 32, 992)  0           conv4_block24_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_conv (Conv2D)   (None, 32, 32, 128)  126976      conv4_block24_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block24_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block24_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block24_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_concat (Concatena (None, 32, 32, 1024) 0           conv4_block23_concat[0][0]       \n",
            "                                                                 conv4_block24_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_bn (BatchNormalization)   (None, 32, 32, 1024) 4096        conv4_block24_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_relu (Activation)         (None, 32, 32, 1024) 0           pool4_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool4_conv (Conv2D)             (None, 32, 32, 512)  524288      pool4_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool4_pool (AveragePooling2D)   (None, 16, 16, 512)  0           pool4_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 16, 16, 512)  2048        pool4_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_relu (Activation (None, 16, 16, 512)  0           conv5_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 16, 16, 128)  65536       conv5_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 16, 16, 128)  512         conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 16, 16, 128)  0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_concat (Concatenat (None, 16, 16, 544)  0           pool4_pool[0][0]                 \n",
            "                                                                 conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_bn (BatchNormali (None, 16, 16, 544)  2176        conv5_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_relu (Activation (None, 16, 16, 544)  0           conv5_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 16, 16, 128)  69632       conv5_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 16, 16, 128)  512         conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 16, 16, 128)  0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_concat (Concatenat (None, 16, 16, 576)  0           conv5_block1_concat[0][0]        \n",
            "                                                                 conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_bn (BatchNormali (None, 16, 16, 576)  2304        conv5_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_relu (Activation (None, 16, 16, 576)  0           conv5_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 16, 16, 128)  73728       conv5_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 16, 16, 128)  512         conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 16, 16, 128)  0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_concat (Concatenat (None, 16, 16, 608)  0           conv5_block2_concat[0][0]        \n",
            "                                                                 conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_bn (BatchNormali (None, 16, 16, 608)  2432        conv5_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_relu (Activation (None, 16, 16, 608)  0           conv5_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_conv (Conv2D)    (None, 16, 16, 128)  77824       conv5_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_bn (BatchNormali (None, 16, 16, 128)  512         conv5_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_relu (Activation (None, 16, 16, 128)  0           conv5_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv5_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_concat (Concatenat (None, 16, 16, 640)  0           conv5_block3_concat[0][0]        \n",
            "                                                                 conv5_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_bn (BatchNormali (None, 16, 16, 640)  2560        conv5_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_relu (Activation (None, 16, 16, 640)  0           conv5_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_conv (Conv2D)    (None, 16, 16, 128)  81920       conv5_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_bn (BatchNormali (None, 16, 16, 128)  512         conv5_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_relu (Activation (None, 16, 16, 128)  0           conv5_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv5_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_concat (Concatenat (None, 16, 16, 672)  0           conv5_block4_concat[0][0]        \n",
            "                                                                 conv5_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_bn (BatchNormali (None, 16, 16, 672)  2688        conv5_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_relu (Activation (None, 16, 16, 672)  0           conv5_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_conv (Conv2D)    (None, 16, 16, 128)  86016       conv5_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_bn (BatchNormali (None, 16, 16, 128)  512         conv5_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_relu (Activation (None, 16, 16, 128)  0           conv5_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv5_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_concat (Concatenat (None, 16, 16, 704)  0           conv5_block5_concat[0][0]        \n",
            "                                                                 conv5_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_bn (BatchNormali (None, 16, 16, 704)  2816        conv5_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_relu (Activation (None, 16, 16, 704)  0           conv5_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_conv (Conv2D)    (None, 16, 16, 128)  90112       conv5_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_bn (BatchNormali (None, 16, 16, 128)  512         conv5_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_relu (Activation (None, 16, 16, 128)  0           conv5_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv5_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_concat (Concatenat (None, 16, 16, 736)  0           conv5_block6_concat[0][0]        \n",
            "                                                                 conv5_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_bn (BatchNormali (None, 16, 16, 736)  2944        conv5_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_relu (Activation (None, 16, 16, 736)  0           conv5_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_conv (Conv2D)    (None, 16, 16, 128)  94208       conv5_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_bn (BatchNormali (None, 16, 16, 128)  512         conv5_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_relu (Activation (None, 16, 16, 128)  0           conv5_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv5_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_concat (Concatenat (None, 16, 16, 768)  0           conv5_block7_concat[0][0]        \n",
            "                                                                 conv5_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_bn (BatchNormali (None, 16, 16, 768)  3072        conv5_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_relu (Activation (None, 16, 16, 768)  0           conv5_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_conv (Conv2D)    (None, 16, 16, 128)  98304       conv5_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_bn (BatchNormali (None, 16, 16, 128)  512         conv5_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_relu (Activation (None, 16, 16, 128)  0           conv5_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv5_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_concat (Concatenat (None, 16, 16, 800)  0           conv5_block8_concat[0][0]        \n",
            "                                                                 conv5_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_bn (BatchNormal (None, 16, 16, 800)  3200        conv5_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_relu (Activatio (None, 16, 16, 800)  0           conv5_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_conv (Conv2D)   (None, 16, 16, 128)  102400      conv5_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_concat (Concatena (None, 16, 16, 832)  0           conv5_block9_concat[0][0]        \n",
            "                                                                 conv5_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_bn (BatchNormal (None, 16, 16, 832)  3328        conv5_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_relu (Activatio (None, 16, 16, 832)  0           conv5_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_conv (Conv2D)   (None, 16, 16, 128)  106496      conv5_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_concat (Concatena (None, 16, 16, 864)  0           conv5_block10_concat[0][0]       \n",
            "                                                                 conv5_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_bn (BatchNormal (None, 16, 16, 864)  3456        conv5_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_relu (Activatio (None, 16, 16, 864)  0           conv5_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_conv (Conv2D)   (None, 16, 16, 128)  110592      conv5_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_concat (Concatena (None, 16, 16, 896)  0           conv5_block11_concat[0][0]       \n",
            "                                                                 conv5_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_bn (BatchNormal (None, 16, 16, 896)  3584        conv5_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_relu (Activatio (None, 16, 16, 896)  0           conv5_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_conv (Conv2D)   (None, 16, 16, 128)  114688      conv5_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_concat (Concatena (None, 16, 16, 928)  0           conv5_block12_concat[0][0]       \n",
            "                                                                 conv5_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_bn (BatchNormal (None, 16, 16, 928)  3712        conv5_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_relu (Activatio (None, 16, 16, 928)  0           conv5_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_conv (Conv2D)   (None, 16, 16, 128)  118784      conv5_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_concat (Concatena (None, 16, 16, 960)  0           conv5_block13_concat[0][0]       \n",
            "                                                                 conv5_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_bn (BatchNormal (None, 16, 16, 960)  3840        conv5_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_relu (Activatio (None, 16, 16, 960)  0           conv5_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_conv (Conv2D)   (None, 16, 16, 128)  122880      conv5_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_concat (Concatena (None, 16, 16, 992)  0           conv5_block14_concat[0][0]       \n",
            "                                                                 conv5_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_bn (BatchNormal (None, 16, 16, 992)  3968        conv5_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_relu (Activatio (None, 16, 16, 992)  0           conv5_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_conv (Conv2D)   (None, 16, 16, 128)  126976      conv5_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_concat (Concatena (None, 16, 16, 1024) 0           conv5_block15_concat[0][0]       \n",
            "                                                                 conv5_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "bn (BatchNormalization)         (None, 16, 16, 1024) 4096        conv5_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 1024)         0           bn[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          262400      global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 6)            1542        dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 1, 1, 6)      0           dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,301,446\n",
            "Trainable params: 263,942\n",
            "Non-trainable params: 7,037,504\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DLJD87KgKamw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T5LVr_5rKam0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "model.compile(optimizer='Nadam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "#output_layers = ['predictions']\n",
        "#model.metrics_tensors += output_layers\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gjhUbCsqN7n3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "564f62cd-0c7e-4cad-d7e3-30ab555f952a"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# initialize the variables and the `tf.assign` ops\n",
        "cbk = CollectOutputAndTarget()\n",
        "'''\n",
        "fetches = [tf.assign(cbk.var_y_true, model.targets[0], validate_shape=False),\n",
        "           tf.assign(cbk.var_y_pred, model.outputs[0], validate_shape=False)]\n",
        "\n",
        "model._function_kwargs = {'fetches': fetches}  # use `model._function_kwargs` if using `Model` instead of `Sequential`\n",
        "'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfetches = [tf.assign(cbk.var_y_true, model.targets[0], validate_shape=False),\\n           tf.assign(cbk.var_y_pred, model.outputs[0], validate_shape=False)]\\n\\nmodel._function_kwargs = {'fetches': fetches}  # use `model._function_kwargs` if using `Model` instead of `Sequential`\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "Rs0vw6rMZuEe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9e1d27b-b5e6-45cc-a882-7078c4da7684"
      },
      "cell_type": "code",
      "source": [
        "# train the model on the new data for a few epochs\n",
        "\n",
        "\n",
        "if os.path.isfile(src+'densenet_30_test.h5'):\n",
        "\n",
        "  model = load_model(src+'densenet_30_test.h5')\n",
        "  print ('model laoded')\n",
        "else:\n",
        "  print ('model not exist')\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model laoded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oiM0Gv4QKam4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10813
        },
        "outputId": "cc5ee438-6aef-4f48-92ba-6503ca1daf39"
      },
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(src+'densenet_test.h5')\n",
        "callback_list = [cbk, checkpoint]\n",
        "\n",
        "for i in range (100):\n",
        "\n",
        "\n",
        "  \n",
        "  train_x,val_x,train_y,val_y = train_test_split(train_data,train_label,test_size=0.2, shuffle=True)\n",
        "  \n",
        "  model.fit(x=train_x, y=train_y, batch_size=32, epochs=30, verbose=1, callbacks=callback_list, validation_split=0.2, shuffle=True)\n",
        "  print ('epoch', i, 'shape=', len(cbk.outputs))\n",
        "  print (cbk.targets)\n",
        "  print (cbk.outputs)\n",
        "\n",
        "  model.save(src+'densenet_30_test.h5')\n",
        "  print ('epoch', i, 'model saved')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1617 samples, validate on 405 samples\n",
            "Epoch 1/30\n",
            "1617/1617 [==============================] - 86s 53ms/step - loss: 1.5254 - acc: 0.3284 - val_loss: 9.5209 - val_acc: 0.2494\n",
            "y_pred = \n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            "y_true = \n",
            " [0 0 1 1 0 5 4 0 5 5 0 4 3 2 5 3 0 5 3 1 0 3 0 5 5 5 4 3 1 0]\n",
            "Epoch 2/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.5017 - acc: 0.3469 - val_loss: 9.4474 - val_acc: 0.2543\n",
            "y_pred = \n",
            " [0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            "y_true = \n",
            " [0 0 1 1 0 5 4 0 5 5 0 4 3 2 5 3 0 5 3 1 0 3 0 5 5 5 4 3 1 0]\n",
            "Epoch 3/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.5021 - acc: 0.3513 - val_loss: 9.1967 - val_acc: 0.2444\n",
            "y_pred = \n",
            " [0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0]\n",
            "y_true = \n",
            " [0 0 1 1 0 5 4 0 5 5 0 4 3 2 5 3 0 5 3 1 0 3 0 5 5 5 4 3 1 0]\n",
            "Epoch 4/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.4910 - acc: 0.3544 - val_loss: 8.9672 - val_acc: 0.2469\n",
            "y_pred = \n",
            " [0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0]\n",
            "y_true = \n",
            " [0 0 1 1 0 5 4 0 5 5 0 4 3 2 5 3 0 5 3 1 0 3 0 5 5 5 4 3 1 0]\n",
            "Epoch 5/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.4916 - acc: 0.3500 - val_loss: 8.8113 - val_acc: 0.2370\n",
            "y_pred = \n",
            " [0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0]\n",
            "y_true = \n",
            " [0 0 1 1 0 5 4 0 5 5 0 4 3 2 5 3 0 5 3 1 0 3 0 5 5 5 4 3 1 0]\n",
            "Epoch 6/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.4802 - acc: 0.3562 - val_loss: 8.5793 - val_acc: 0.2370\n",
            "y_pred = \n",
            " [0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0]\n",
            "y_true = \n",
            " [0 0 1 1 0 5 4 0 5 5 0 4 3 2 5 3 0 5 3 1 0 3 0 5 5 5 4 3 1 0]\n",
            "Epoch 7/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.4544 - acc: 0.3680 - val_loss: 8.7823 - val_acc: 0.2370\n",
            "y_pred = \n",
            " [0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0]\n",
            "y_true = \n",
            " [0 0 1 1 0 5 4 0 5 5 0 4 3 2 5 3 0 5 3 1 0 3 0 5 5 5 4 3 1 0]\n",
            "Epoch 8/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.4396 - acc: 0.3822 - val_loss: 9.0143 - val_acc: 0.2395\n",
            "y_pred = \n",
            " [0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0]\n",
            "y_true = \n",
            " [0 0 1 1 0 5 4 0 5 5 0 4 3 2 5 3 0 5 3 1 0 3 0 5 5 5 4 3 1 0]\n",
            "Epoch 9/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.4266 - acc: 0.3921 - val_loss: 9.0905 - val_acc: 0.2444\n",
            "y_pred = \n",
            " [0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0]\n",
            "y_true = \n",
            " [0 0 1 1 0 5 4 0 5 5 0 4 3 2 5 3 0 5 3 1 0 3 0 5 5 5 4 3 1 0]\n",
            "Epoch 10/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.4253 - acc: 0.3779 - val_loss: 8.9944 - val_acc: 0.2370\n",
            "y_pred = \n",
            " [0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0]\n",
            "y_true = \n",
            " [0 0 1 1 0 5 4 0 5 5 0 4 3 2 5 3 0 5 3 1 0 3 0 5 5 5 4 3 1 0]\n",
            "Epoch 11/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.4363 - acc: 0.3902 - val_loss: 8.9749 - val_acc: 0.2370\n",
            "y_pred = \n",
            " [0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0]\n",
            "y_true = \n",
            " [0 0 1 1 0 5 4 0 5 5 0 4 3 2 5 3 0 5 3 1 0 3 0 5 5 5 4 3 1 0]\n",
            "Epoch 12/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.4084 - acc: 0.3976 - val_loss: 8.9278 - val_acc: 0.2370\n",
            "y_pred = \n",
            " [0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0]\n",
            "y_true = \n",
            " [0 0 1 1 0 5 4 0 5 5 0 4 3 2 5 3 0 5 3 1 0 3 0 5 5 5 4 3 1 0]\n",
            "Epoch 13/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.3895 - acc: 0.4038 - val_loss: 8.8646 - val_acc: 0.2395\n",
            "y_pred = \n",
            " [0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0]\n",
            "y_true = \n",
            " [0 0 1 1 0 5 4 0 5 5 0 4 3 2 5 3 0 5 3 1 0 3 0 5 5 5 4 3 1 0]\n",
            "Epoch 14/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.3876 - acc: 0.3884 - val_loss: 8.7937 - val_acc: 0.2346\n",
            "y_pred = \n",
            " [0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0]\n",
            "y_true = \n",
            " [0 0 1 1 0 5 4 0 5 5 0 4 3 2 5 3 0 5 3 1 0 3 0 5 5 5 4 3 1 0]\n",
            "Epoch 15/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.3870 - acc: 0.4082 - val_loss: 8.9322 - val_acc: 0.2370\n",
            "y_pred = \n",
            " [0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0]\n",
            "y_true = \n",
            " [0 0 1 1 0 5 4 0 5 5 0 4 3 2 5 3 0 5 3 1 0 3 0 5 5 5 4 3 1 0]\n",
            "Epoch 16/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.3512 - acc: 0.4057 - val_loss: 9.0378 - val_acc: 0.2346\n",
            "y_pred = \n",
            " [0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0]\n",
            "y_true = \n",
            " [0 0 1 1 0 5 4 0 5 5 0 4 3 2 5 3 0 5 3 1 0 3 0 5 5 5 4 3 1 0]\n",
            "Epoch 17/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.3664 - acc: 0.4224 - val_loss: 8.8776 - val_acc: 0.2321\n",
            "y_pred = \n",
            " [0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0]\n",
            "y_true = \n",
            " [0 0 1 1 0 5 4 0 5 5 0 4 3 2 5 3 0 5 3 1 0 3 0 5 5 5 4 3 1 0]\n",
            "Epoch 18/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.3448 - acc: 0.4280 - val_loss: 9.0821 - val_acc: 0.2420\n",
            "y_pred = \n",
            " [0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0]\n",
            "y_true = \n",
            " [0 0 1 1 0 5 4 0 5 5 0 4 3 2 5 3 0 5 3 1 0 3 0 5 5 5 4 3 1 0]\n",
            "Epoch 19/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.3259 - acc: 0.4354 - val_loss: 8.9670 - val_acc: 0.2370\n",
            "y_pred = \n",
            " [0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0]\n",
            "y_true = \n",
            " [0 0 1 1 0 5 4 0 5 5 0 4 3 2 5 3 0 5 3 1 0 3 0 5 5 5 4 3 1 0]\n",
            "Epoch 20/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.3202 - acc: 0.4428 - val_loss: 8.9506 - val_acc: 0.2420\n",
            "y_pred = \n",
            " [0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0]\n",
            "y_true = \n",
            " [0 0 1 1 0 5 4 0 5 5 0 4 3 2 5 3 0 5 3 1 0 3 0 5 5 5 4 3 1 0]\n",
            "Epoch 21/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.2940 - acc: 0.4477 - val_loss: 8.7136 - val_acc: 0.2395\n",
            "y_pred = \n",
            " [0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0]\n",
            "y_true = \n",
            " [0 0 1 1 0 5 4 0 5 5 0 4 3 2 5 3 0 5 3 1 0 3 0 5 5 5 4 3 1 0]\n",
            "Epoch 22/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.2952 - acc: 0.4496 - val_loss: 8.9210 - val_acc: 0.2296\n",
            "y_pred = \n",
            " [0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0]\n",
            "y_true = \n",
            " [0 0 1 1 0 5 4 0 5 5 0 4 3 2 5 3 0 5 3 1 0 3 0 5 5 5 4 3 1 0]\n",
            "Epoch 23/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.3012 - acc: 0.4644 - val_loss: 8.9864 - val_acc: 0.2346\n",
            "y_pred = \n",
            " [0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0]\n",
            "y_true = \n",
            " [0 0 1 1 0 5 4 0 5 5 0 4 3 2 5 3 0 5 3 1 0 3 0 5 5 5 4 3 1 0]\n",
            "Epoch 24/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.2557 - acc: 0.4725 - val_loss: 8.7372 - val_acc: 0.2346\n",
            "y_pred = \n",
            " [0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0]\n",
            "y_true = \n",
            " [0 0 1 1 0 5 4 0 5 5 0 4 3 2 5 3 0 5 3 1 0 3 0 5 5 5 4 3 1 0]\n",
            "Epoch 25/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.2835 - acc: 0.4484 - val_loss: 8.9061 - val_acc: 0.2296\n",
            "y_pred = \n",
            " [0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0]\n",
            "y_true = \n",
            " [0 0 1 1 0 5 4 0 5 5 0 4 3 2 5 3 0 5 3 1 0 3 0 5 5 5 4 3 1 0]\n",
            "Epoch 26/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.2611 - acc: 0.4737 - val_loss: 8.7983 - val_acc: 0.2272\n",
            "y_pred = \n",
            " [0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0]\n",
            "y_true = \n",
            " [0 0 1 1 0 5 4 0 5 5 0 4 3 2 5 3 0 5 3 1 0 3 0 5 5 5 4 3 1 0]\n",
            "Epoch 27/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.2434 - acc: 0.4892 - val_loss: 8.5518 - val_acc: 0.2296\n",
            "y_pred = \n",
            " [0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0]\n",
            "y_true = \n",
            " [0 0 1 1 0 5 4 0 5 5 0 4 3 2 5 3 0 5 3 1 0 3 0 5 5 5 4 3 1 0]\n",
            "Epoch 28/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.2347 - acc: 0.4731 - val_loss: 8.5964 - val_acc: 0.2321\n",
            "y_pred = \n",
            " [0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0]\n",
            "y_true = \n",
            " [0 0 1 1 0 5 4 0 5 5 0 4 3 2 5 3 0 5 3 1 0 3 0 5 5 5 4 3 1 0]\n",
            "Epoch 29/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.2044 - acc: 0.4960 - val_loss: 8.7466 - val_acc: 0.2346\n",
            "y_pred = \n",
            " [0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0]\n",
            "y_true = \n",
            " [0 0 1 1 0 5 4 0 5 5 0 4 3 2 5 3 0 5 3 1 0 3 0 5 5 5 4 3 1 0]\n",
            "Epoch 30/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.2264 - acc: 0.4873 - val_loss: 8.5238 - val_acc: 0.2247\n",
            "y_pred = \n",
            " [0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0]\n",
            "y_true = \n",
            " [0 0 1 1 0 5 4 0 5 5 0 4 3 2 5 3 0 5 3 1 0 3 0 5 5 5 4 3 1 0]\n",
            "epoch 0 shape= 0\n",
            "[]\n",
            "[]\n",
            "epoch 0 model saved\n",
            "Train on 1617 samples, validate on 405 samples\n",
            "Epoch 1/30\n",
            "1617/1617 [==============================] - 86s 53ms/step - loss: 1.4526 - acc: 0.4156 - val_loss: 8.5309 - val_acc: 0.2617\n",
            "y_pred = \n",
            " [0 0 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 0 0 0 0 1 3 0 1 0]\n",
            "y_true = \n",
            " [1 1 5 3 5 5 5 0 0 0 3 4 5 0 0 5 1 5 3 0 0 0 0 1 3 5 1 1 1 0]\n",
            "Epoch 2/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.3770 - acc: 0.4403 - val_loss: 8.4054 - val_acc: 0.2617\n",
            "y_pred = \n",
            " [0 0 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 0 0 0 0 1 3 0 1 0]\n",
            "y_true = \n",
            " [1 1 5 3 5 5 5 0 0 0 3 4 5 0 0 5 1 5 3 0 0 0 0 1 3 5 1 1 1 0]\n",
            "Epoch 3/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.3611 - acc: 0.4255 - val_loss: 8.5244 - val_acc: 0.2617\n",
            "y_pred = \n",
            " [0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 0 0 0 0 1 3 0 1 0]\n",
            "y_true = \n",
            " [1 1 5 3 5 5 5 0 0 0 3 4 5 0 0 5 1 5 3 0 0 0 0 1 3 5 1 1 1 0]\n",
            "Epoch 4/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.3686 - acc: 0.4273 - val_loss: 8.1569 - val_acc: 0.2568\n",
            "y_pred = \n",
            " [0 0 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 3 1 0 0 0 0 1 3 0 1 0]\n",
            "y_true = \n",
            " [1 1 5 3 5 5 5 0 0 0 3 4 5 0 0 5 1 5 3 0 0 0 0 1 3 5 1 1 1 0]\n",
            "Epoch 5/30\n",
            "1617/1617 [==============================] - 86s 53ms/step - loss: 1.3256 - acc: 0.4527 - val_loss: 8.0147 - val_acc: 0.2395\n",
            "y_pred = \n",
            " [0 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 3 1 0 0 0 0 1 3 0 1 0]\n",
            "y_true = \n",
            " [1 1 5 3 5 5 5 0 0 0 3 4 5 0 0 5 1 5 3 0 0 0 0 1 3 5 1 1 1 0]\n",
            "Epoch 6/30\n",
            "1617/1617 [==============================] - 86s 53ms/step - loss: 1.3331 - acc: 0.4539 - val_loss: 8.1767 - val_acc: 0.2247\n",
            "y_pred = \n",
            " [5 0 1 1 1 1 1 1 1 4 1 0 1 1 0 1 1 1 1 3 1 1 0 1 0 1 3 0 1 0]\n",
            "y_true = \n",
            " [1 1 5 3 5 5 5 0 0 0 3 4 5 0 0 5 1 5 3 0 0 0 0 1 3 5 1 1 1 0]\n",
            "Epoch 7/30\n",
            "1617/1617 [==============================] - 86s 53ms/step - loss: 1.2761 - acc: 0.4620 - val_loss: 8.1951 - val_acc: 0.2222\n",
            "y_pred = \n",
            " [1 0 1 1 1 1 1 1 1 4 1 0 1 1 0 1 1 1 1 3 1 1 0 1 0 1 3 0 1 0]\n",
            "y_true = \n",
            " [1 1 5 3 5 5 5 0 0 0 3 4 5 0 0 5 1 5 3 0 0 0 0 1 3 5 1 1 1 0]\n",
            "Epoch 8/30\n",
            "1617/1617 [==============================] - 86s 53ms/step - loss: 1.2831 - acc: 0.4706 - val_loss: 8.3237 - val_acc: 0.2272\n",
            "y_pred = \n",
            " [1 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 3 1 1 0 1 0 1 3 0 1 0]\n",
            "y_true = \n",
            " [1 1 5 3 5 5 5 0 0 0 3 4 5 0 0 5 1 5 3 0 0 0 0 1 3 5 1 1 1 0]\n",
            "Epoch 9/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.2947 - acc: 0.4576 - val_loss: 8.1526 - val_acc: 0.2247\n",
            "y_pred = \n",
            " [5 0 1 1 1 1 1 1 1 4 1 0 1 1 0 1 1 1 1 3 1 1 0 1 0 1 3 0 1 0]\n",
            "y_true = \n",
            " [1 1 5 3 5 5 5 0 0 0 3 4 5 0 0 5 1 5 3 0 0 0 0 1 3 5 1 1 1 0]\n",
            "Epoch 10/30\n",
            "1617/1617 [==============================] - 86s 53ms/step - loss: 1.2518 - acc: 0.4787 - val_loss: 8.2082 - val_acc: 0.2321\n",
            "y_pred = \n",
            " [1 0 1 1 1 1 1 1 1 4 1 0 1 1 0 1 1 1 1 3 1 1 0 1 0 1 3 1 1 0]\n",
            "y_true = \n",
            " [1 1 5 3 5 5 5 0 0 0 3 4 5 0 0 5 1 5 3 0 0 0 0 1 3 5 1 1 1 0]\n",
            "Epoch 11/30\n",
            "1617/1617 [==============================] - 86s 53ms/step - loss: 1.2305 - acc: 0.4774 - val_loss: 8.3165 - val_acc: 0.2247\n",
            "y_pred = \n",
            " [1 0 1 1 1 1 1 1 1 4 1 0 1 1 0 1 1 1 1 3 1 1 0 1 0 1 3 0 1 0]\n",
            "y_true = \n",
            " [1 1 5 3 5 5 5 0 0 0 3 4 5 0 0 5 1 5 3 0 0 0 0 1 3 5 1 1 1 0]\n",
            "Epoch 12/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.2585 - acc: 0.4811 - val_loss: 8.0360 - val_acc: 0.2247\n",
            "y_pred = \n",
            " [1 0 1 1 1 1 1 1 1 4 1 0 1 1 0 1 1 1 1 3 1 1 0 1 0 1 3 0 1 0]\n",
            "y_true = \n",
            " [1 1 5 3 5 5 5 0 0 0 3 4 5 0 0 5 1 5 3 0 0 0 0 1 3 5 1 1 1 0]\n",
            "Epoch 13/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.2365 - acc: 0.4947 - val_loss: 8.2785 - val_acc: 0.2198\n",
            "y_pred = \n",
            " [1 0 1 1 1 1 1 1 1 4 1 1 1 1 0 1 1 1 1 3 1 1 0 1 0 1 3 0 1 0]\n",
            "y_true = \n",
            " [1 1 5 3 5 5 5 0 0 0 3 4 5 0 0 5 1 5 3 0 0 0 0 1 3 5 1 1 1 0]\n",
            "Epoch 14/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.1882 - acc: 0.5083 - val_loss: 8.2420 - val_acc: 0.2173\n",
            "y_pred = \n",
            " [1 0 1 1 1 1 1 1 1 4 1 1 1 1 0 1 1 1 1 3 1 1 0 1 0 1 3 1 1 0]\n",
            "y_true = \n",
            " [1 1 5 3 5 5 5 0 0 0 3 4 5 0 0 5 1 5 3 0 0 0 0 1 3 5 1 1 1 0]\n",
            "Epoch 15/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.2206 - acc: 0.5158 - val_loss: 8.2014 - val_acc: 0.2123\n",
            "y_pred = \n",
            " [1 4 1 1 1 1 1 1 1 4 1 1 1 1 0 1 1 1 1 3 1 1 0 1 0 1 3 1 1 0]\n",
            "y_true = \n",
            " [1 1 5 3 5 5 5 0 0 0 3 4 5 0 0 5 1 5 3 0 0 0 0 1 3 5 1 1 1 0]\n",
            "Epoch 16/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.1847 - acc: 0.5090 - val_loss: 8.2233 - val_acc: 0.2173\n",
            "y_pred = \n",
            " [5 0 1 1 1 1 1 1 1 4 1 1 1 1 0 1 1 1 1 3 1 1 0 1 0 1 3 1 1 0]\n",
            "y_true = \n",
            " [1 1 5 3 5 5 5 0 0 0 3 4 5 0 0 5 1 5 3 0 0 0 0 1 3 5 1 1 1 0]\n",
            "Epoch 17/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.1546 - acc: 0.5213 - val_loss: 8.3355 - val_acc: 0.2198\n",
            "y_pred = \n",
            " [1 0 1 1 1 1 1 1 1 4 1 0 1 1 0 1 1 1 1 3 1 1 0 1 0 1 3 1 1 0]\n",
            "y_true = \n",
            " [1 1 5 3 5 5 5 0 0 0 3 4 5 0 0 5 1 5 3 0 0 0 0 1 3 5 1 1 1 0]\n",
            "Epoch 18/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.1477 - acc: 0.5269 - val_loss: 8.5796 - val_acc: 0.2222\n",
            "y_pred = \n",
            " [1 4 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0]\n",
            "y_true = \n",
            " [1 1 5 3 5 5 5 0 0 0 3 4 5 0 0 5 1 5 3 0 0 0 0 1 3 5 1 1 1 0]\n",
            "Epoch 19/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.1277 - acc: 0.5325 - val_loss: 8.4408 - val_acc: 0.2247\n",
            "y_pred = \n",
            " [1 4 1 1 1 1 1 1 1 4 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0]\n",
            "y_true = \n",
            " [1 1 5 3 5 5 5 0 0 0 3 4 5 0 0 5 1 5 3 0 0 0 0 1 3 5 1 1 1 0]\n",
            "Epoch 20/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.1134 - acc: 0.5331 - val_loss: 8.4168 - val_acc: 0.2173\n",
            "y_pred = \n",
            " [1 5 1 1 1 1 1 1 1 4 1 1 1 1 5 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0]\n",
            "y_true = \n",
            " [1 1 5 3 5 5 5 0 0 0 3 4 5 0 0 5 1 5 3 0 0 0 0 1 3 5 1 1 1 0]\n",
            "Epoch 21/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.1124 - acc: 0.5232 - val_loss: 8.4796 - val_acc: 0.2173\n",
            "y_pred = \n",
            " [1 5 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 3 1 1 0]\n",
            "y_true = \n",
            " [1 1 5 3 5 5 5 0 0 0 3 4 5 0 0 5 1 5 3 0 0 0 0 1 3 5 1 1 1 0]\n",
            "Epoch 22/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.1182 - acc: 0.5448 - val_loss: 8.7039 - val_acc: 0.2272\n",
            "y_pred = \n",
            " [1 0 1 1 1 1 1 1 1 4 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0]\n",
            "y_true = \n",
            " [1 1 5 3 5 5 5 0 0 0 3 4 5 0 0 5 1 5 3 0 0 0 0 1 3 5 1 1 1 0]\n",
            "Epoch 23/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.0918 - acc: 0.5634 - val_loss: 8.6922 - val_acc: 0.2173\n",
            "y_pred = \n",
            " [1 4 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0]\n",
            "y_true = \n",
            " [1 1 5 3 5 5 5 0 0 0 3 4 5 0 0 5 1 5 3 0 0 0 0 1 3 5 1 1 1 0]\n",
            "Epoch 24/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.1117 - acc: 0.5541 - val_loss: 8.7749 - val_acc: 0.2247\n",
            "y_pred = \n",
            " [1 4 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0]\n",
            "y_true = \n",
            " [1 1 5 3 5 5 5 0 0 0 3 4 5 0 0 5 1 5 3 0 0 0 0 1 3 5 1 1 1 0]\n",
            "Epoch 25/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.0771 - acc: 0.5535 - val_loss: 8.6656 - val_acc: 0.2148\n",
            "y_pred = \n",
            " [1 4 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0]\n",
            "y_true = \n",
            " [1 1 5 3 5 5 5 0 0 0 3 4 5 0 0 5 1 5 3 0 0 0 0 1 3 5 1 1 1 0]\n",
            "Epoch 26/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.0320 - acc: 0.5850 - val_loss: 8.7301 - val_acc: 0.2272\n",
            "y_pred = \n",
            " [1 4 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0]\n",
            "y_true = \n",
            " [1 1 5 3 5 5 5 0 0 0 3 4 5 0 0 5 1 5 3 0 0 0 0 1 3 5 1 1 1 0]\n",
            "Epoch 27/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.0404 - acc: 0.5857 - val_loss: 8.6081 - val_acc: 0.2173\n",
            "y_pred = \n",
            " [1 4 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 1 3 1 1 0 1 0 1 3 1 1 0]\n",
            "y_true = \n",
            " [1 1 5 3 5 5 5 0 0 0 3 4 5 0 0 5 1 5 3 0 0 0 0 1 3 5 1 1 1 0]\n",
            "Epoch 28/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.0288 - acc: 0.5850 - val_loss: 8.5944 - val_acc: 0.2099\n",
            "y_pred = \n",
            " [1 0 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 1 3 1 1 0 1 0 1 3 1 1 0]\n",
            "y_true = \n",
            " [1 1 5 3 5 5 5 0 0 0 3 4 5 0 0 5 1 5 3 0 0 0 0 1 3 5 1 1 1 0]\n",
            "Epoch 29/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.0429 - acc: 0.5739 - val_loss: 8.7524 - val_acc: 0.2074\n",
            "y_pred = \n",
            " [1 4 1 1 1 1 1 1 1 4 1 0 1 1 1 1 1 1 1 3 1 1 0 1 0 1 3 1 1 0]\n",
            "y_true = \n",
            " [1 1 5 3 5 5 5 0 0 0 3 4 5 0 0 5 1 5 3 0 0 0 0 1 3 5 1 1 1 0]\n",
            "Epoch 30/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.0229 - acc: 0.5980 - val_loss: 8.7310 - val_acc: 0.2123\n",
            "y_pred = \n",
            " [1 0 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 1 3 1 1 0 1 0 1 3 1 1 0]\n",
            "y_true = \n",
            " [1 1 5 3 5 5 5 0 0 0 3 4 5 0 0 5 1 5 3 0 0 0 0 1 3 5 1 1 1 0]\n",
            "epoch 1 shape= 0\n",
            "[]\n",
            "[]\n",
            "epoch 1 model saved\n",
            "Train on 1617 samples, validate on 405 samples\n",
            "Epoch 1/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.3207 - acc: 0.4855 - val_loss: 9.4745 - val_acc: 0.1704\n",
            "y_pred = \n",
            " [1 1 1 1 1 0 1 1 1 1 1 3 1 1 2 1 1 0 1 1 1 1 1 1 1 1 1 1 4 1]\n",
            "y_true = \n",
            " [3 1 0 5 1 5 1 5 0 5 3 2 5 0 0 4 5 1 0 3 0 1 1 4 4 0 0 1 0 0]\n",
            "Epoch 2/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.2590 - acc: 0.4836 - val_loss: 9.0290 - val_acc: 0.1778\n",
            "y_pred = \n",
            " [1 0 1 1 1 0 5 1 1 1 0 3 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 3 1]\n",
            "y_true = \n",
            " [3 1 0 5 1 5 1 5 0 5 3 2 5 0 0 4 5 1 0 3 0 1 1 4 4 0 0 1 0 0]\n",
            "Epoch 3/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.1943 - acc: 0.5114 - val_loss: 8.7072 - val_acc: 0.1901\n",
            "y_pred = \n",
            " [1 0 1 1 1 0 5 1 1 1 3 3 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 4 1]\n",
            "y_true = \n",
            " [3 1 0 5 1 5 1 5 0 5 3 2 5 0 0 4 5 1 0 3 0 1 1 4 4 0 0 1 0 0]\n",
            "Epoch 4/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.1900 - acc: 0.5114 - val_loss: 8.6689 - val_acc: 0.1926\n",
            "y_pred = \n",
            " [1 4 1 1 1 0 5 1 1 1 3 3 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 4 1]\n",
            "y_true = \n",
            " [3 1 0 5 1 5 1 5 0 5 3 2 5 0 0 4 5 1 0 3 0 1 1 4 4 0 0 1 0 0]\n",
            "Epoch 5/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.1573 - acc: 0.5269 - val_loss: 8.6636 - val_acc: 0.1877\n",
            "y_pred = \n",
            " [1 4 1 1 1 0 5 1 1 1 3 3 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 4 1]\n",
            "y_true = \n",
            " [3 1 0 5 1 5 1 5 0 5 3 2 5 0 0 4 5 1 0 3 0 1 1 4 4 0 0 1 0 0]\n",
            "Epoch 6/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.1543 - acc: 0.5417 - val_loss: 8.8745 - val_acc: 0.1802\n",
            "y_pred = \n",
            " [1 4 1 1 1 0 5 1 1 1 3 3 1 1 2 1 1 0 1 1 1 1 1 1 1 1 1 1 4 1]\n",
            "y_true = \n",
            " [3 1 0 5 1 5 1 5 0 5 3 2 5 0 0 4 5 1 0 3 0 1 1 4 4 0 0 1 0 0]\n",
            "Epoch 7/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.1142 - acc: 0.5380 - val_loss: 9.2327 - val_acc: 0.1704\n",
            "y_pred = \n",
            " [1 4 1 1 1 0 5 1 1 1 3 3 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 4 1]\n",
            "y_true = \n",
            " [3 1 0 5 1 5 1 5 0 5 3 2 5 0 0 4 5 1 0 3 0 1 1 4 4 0 0 1 0 0]\n",
            "Epoch 8/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.1301 - acc: 0.5325 - val_loss: 8.9746 - val_acc: 0.1654\n",
            "y_pred = \n",
            " [1 4 1 1 1 0 5 1 1 1 3 3 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 4 1]\n",
            "y_true = \n",
            " [3 1 0 5 1 5 1 5 0 5 3 2 5 0 0 4 5 1 0 3 0 1 1 4 4 0 0 1 0 0]\n",
            "Epoch 9/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.1229 - acc: 0.5467 - val_loss: 9.0598 - val_acc: 0.1679\n",
            "y_pred = \n",
            " [1 4 1 1 1 0 5 1 1 1 3 3 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "y_true = \n",
            " [3 1 0 5 1 5 1 5 0 5 3 2 5 0 0 4 5 1 0 3 0 1 1 4 4 0 0 1 0 0]\n",
            "Epoch 10/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.0785 - acc: 0.5751 - val_loss: 8.5263 - val_acc: 0.1877\n",
            "y_pred = \n",
            " [1 4 1 1 1 0 5 1 1 1 3 3 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 4 1]\n",
            "y_true = \n",
            " [3 1 0 5 1 5 1 5 0 5 3 2 5 0 0 4 5 1 0 3 0 1 1 4 4 0 0 1 0 0]\n",
            "Epoch 11/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.0577 - acc: 0.5652 - val_loss: 8.6823 - val_acc: 0.1802\n",
            "y_pred = \n",
            " [1 4 1 1 1 0 5 1 1 1 3 3 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 4 1]\n",
            "y_true = \n",
            " [3 1 0 5 1 5 1 5 0 5 3 2 5 0 0 4 5 1 0 3 0 1 1 4 4 0 0 1 0 0]\n",
            "Epoch 12/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.0629 - acc: 0.5690 - val_loss: 8.9319 - val_acc: 0.1679\n",
            "y_pred = \n",
            " [1 4 1 1 1 0 5 1 1 1 3 3 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 4 1]\n",
            "y_true = \n",
            " [3 1 0 5 1 5 1 5 0 5 3 2 5 0 0 4 5 1 0 3 0 1 1 4 4 0 0 1 0 0]\n",
            "Epoch 13/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.0851 - acc: 0.5609 - val_loss: 8.8510 - val_acc: 0.1753\n",
            "y_pred = \n",
            " [1 4 1 1 1 1 5 1 1 1 3 3 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 4 1]\n",
            "y_true = \n",
            " [3 1 0 5 1 5 1 5 0 5 3 2 5 0 0 4 5 1 0 3 0 1 1 4 4 0 0 1 0 0]\n",
            "Epoch 14/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.0566 - acc: 0.5832 - val_loss: 9.0340 - val_acc: 0.1728\n",
            "y_pred = \n",
            " [1 4 1 1 1 1 5 1 1 1 3 3 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 4 1]\n",
            "y_true = \n",
            " [3 1 0 5 1 5 1 5 0 5 3 2 5 0 0 4 5 1 0 3 0 1 1 4 4 0 0 1 0 0]\n",
            "Epoch 15/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.0439 - acc: 0.5776 - val_loss: 9.1137 - val_acc: 0.1679\n",
            "y_pred = \n",
            " [1 4 1 1 1 1 5 1 1 1 3 3 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 4 1]\n",
            "y_true = \n",
            " [3 1 0 5 1 5 1 5 0 5 3 2 5 0 0 4 5 1 0 3 0 1 1 4 4 0 0 1 0 0]\n",
            "Epoch 16/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.0144 - acc: 0.5980 - val_loss: 8.8857 - val_acc: 0.1753\n",
            "y_pred = \n",
            " [1 4 1 3 1 1 5 1 1 1 3 3 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 4 1]\n",
            "y_true = \n",
            " [3 1 0 5 1 5 1 5 0 5 3 2 5 0 0 4 5 1 0 3 0 1 1 4 4 0 0 1 0 0]\n",
            "Epoch 17/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 1.0224 - acc: 0.5925 - val_loss: 9.0176 - val_acc: 0.1654\n",
            "y_pred = \n",
            " [1 4 1 1 1 0 4 1 1 1 3 3 1 4 0 1 1 0 1 1 1 1 1 4 1 1 1 1 4 1]\n",
            "y_true = \n",
            " [3 1 0 5 1 5 1 5 0 5 3 2 5 0 0 4 5 1 0 3 0 1 1 4 4 0 0 1 0 0]\n",
            "Epoch 18/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 0.9875 - acc: 0.6005 - val_loss: 9.1091 - val_acc: 0.1679\n",
            "y_pred = \n",
            " [1 4 1 1 1 0 5 1 1 1 3 3 1 1 0 1 1 0 1 1 1 1 1 4 1 1 1 1 4 1]\n",
            "y_true = \n",
            " [3 1 0 5 1 5 1 5 0 5 3 2 5 0 0 4 5 1 0 3 0 1 1 4 4 0 0 1 0 0]\n",
            "Epoch 19/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 0.9502 - acc: 0.6302 - val_loss: 9.3057 - val_acc: 0.1580\n",
            "y_pred = \n",
            " [1 4 1 1 1 0 4 1 1 1 3 3 1 4 0 1 1 0 1 1 1 1 1 4 1 1 1 1 4 1]\n",
            "y_true = \n",
            " [3 1 0 5 1 5 1 5 0 5 3 2 5 0 0 4 5 1 0 3 0 1 1 4 4 0 0 1 0 0]\n",
            "Epoch 20/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 0.9476 - acc: 0.6289 - val_loss: 9.2530 - val_acc: 0.1654\n",
            "y_pred = \n",
            " [1 4 1 1 1 0 4 1 1 1 3 3 1 1 0 1 1 0 1 1 1 1 1 4 1 1 1 1 4 1]\n",
            "y_true = \n",
            " [3 1 0 5 1 5 1 5 0 5 3 2 5 0 0 4 5 1 0 3 0 1 1 4 4 0 0 1 0 0]\n",
            "Epoch 21/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 0.9991 - acc: 0.5937 - val_loss: 9.4477 - val_acc: 0.1630\n",
            "y_pred = \n",
            " [1 4 1 1 1 1 4 1 1 1 3 3 1 1 0 1 1 0 1 1 1 1 1 4 1 1 1 1 4 1]\n",
            "y_true = \n",
            " [3 1 0 5 1 5 1 5 0 5 3 2 5 0 0 4 5 1 0 3 0 1 1 4 4 0 0 1 0 0]\n",
            "Epoch 22/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 0.9440 - acc: 0.6203 - val_loss: 9.5849 - val_acc: 0.1728\n",
            "y_pred = \n",
            " [1 4 1 1 1 0 4 1 1 1 3 3 1 4 0 1 1 0 1 1 1 1 1 4 1 1 3 1 4 1]\n",
            "y_true = \n",
            " [3 1 0 5 1 5 1 5 0 5 3 2 5 0 0 4 5 1 0 3 0 1 1 4 4 0 0 1 0 0]\n",
            "Epoch 23/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 0.9228 - acc: 0.6209 - val_loss: 9.5711 - val_acc: 0.1753\n",
            "y_pred = \n",
            " [1 4 1 1 1 0 4 1 1 1 3 3 1 4 0 1 1 0 1 1 1 1 1 4 1 1 1 1 4 1]\n",
            "y_true = \n",
            " [3 1 0 5 1 5 1 5 0 5 3 2 5 0 0 4 5 1 0 3 0 1 1 4 4 0 0 1 0 0]\n",
            "Epoch 24/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 0.9689 - acc: 0.6190 - val_loss: 9.2830 - val_acc: 0.1580\n",
            "y_pred = \n",
            " [1 4 1 1 1 0 4 1 1 1 3 3 1 4 0 1 1 0 1 1 1 1 1 4 1 1 1 1 4 1]\n",
            "y_true = \n",
            " [3 1 0 5 1 5 1 5 0 5 3 2 5 0 0 4 5 1 0 3 0 1 1 4 4 0 0 1 0 0]\n",
            "Epoch 25/30\n",
            "1617/1617 [==============================] - 86s 53ms/step - loss: 0.9625 - acc: 0.6073 - val_loss: 9.3733 - val_acc: 0.1654\n",
            "y_pred = \n",
            " [1 4 1 1 1 0 4 1 1 1 3 3 1 4 4 1 1 0 1 1 1 1 1 4 1 1 1 1 4 1]\n",
            "y_true = \n",
            " [3 1 0 5 1 5 1 5 0 5 3 2 5 0 0 4 5 1 0 3 0 1 1 4 4 0 0 1 0 0]\n",
            "Epoch 26/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 0.9015 - acc: 0.6401 - val_loss: 9.4682 - val_acc: 0.1630\n",
            "y_pred = \n",
            " [1 4 1 1 1 0 4 1 1 1 3 3 1 4 0 1 1 0 1 1 1 1 1 4 1 1 1 1 4 1]\n",
            "y_true = \n",
            " [3 1 0 5 1 5 1 5 0 5 3 2 5 0 0 4 5 1 0 3 0 1 1 4 4 0 0 1 0 0]\n",
            "Epoch 27/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 0.9056 - acc: 0.6364 - val_loss: 9.4875 - val_acc: 0.1679\n",
            "y_pred = \n",
            " [1 4 1 1 1 1 4 1 1 1 3 3 1 1 0 1 1 0 1 1 1 1 1 4 1 1 1 1 4 1]\n",
            "y_true = \n",
            " [3 1 0 5 1 5 1 5 0 5 3 2 5 0 0 4 5 1 0 3 0 1 1 4 4 0 0 1 0 0]\n",
            "Epoch 28/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 0.8990 - acc: 0.6413 - val_loss: 9.6495 - val_acc: 0.1704\n",
            "y_pred = \n",
            " [1 4 1 1 1 0 4 1 1 1 3 3 1 3 0 1 1 0 1 1 1 1 1 4 1 1 1 1 4 1]\n",
            "y_true = \n",
            " [3 1 0 5 1 5 1 5 0 5 3 2 5 0 0 4 5 1 0 3 0 1 1 4 4 0 0 1 0 0]\n",
            "Epoch 29/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 0.8552 - acc: 0.6555 - val_loss: 9.8654 - val_acc: 0.1630\n",
            "y_pred = \n",
            " [1 4 1 1 1 1 4 1 1 1 3 3 1 1 4 1 1 0 1 1 1 1 1 4 1 1 1 1 4 1]\n",
            "y_true = \n",
            " [3 1 0 5 1 5 1 5 0 5 3 2 5 0 0 4 5 1 0 3 0 1 1 4 4 0 0 1 0 0]\n",
            "Epoch 30/30\n",
            "1617/1617 [==============================] - 85s 53ms/step - loss: 0.9209 - acc: 0.6370 - val_loss: 9.6964 - val_acc: 0.1654\n",
            "y_pred = \n",
            " [1 4 1 1 1 1 4 1 1 1 3 3 1 1 4 1 1 0 1 1 1 1 1 4 1 1 1 1 4 1]\n",
            "y_true = \n",
            " [3 1 0 5 1 5 1 5 0 5 3 2 5 0 0 4 5 1 0 3 0 1 1 4 4 0 0 1 0 0]\n",
            "epoch 2 shape= 0\n",
            "[]\n",
            "[]\n",
            "epoch 2 model saved\n",
            "Train on 1617 samples, validate on 405 samples\n",
            "Epoch 1/30\n",
            " 128/1617 [=>............................] - ETA: 57s - loss: 1.2083 - acc: 0.5312"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-6994df3f25a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ier2J4W-Kanh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RSA-V9bq7Qxx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def shuffle_list(s,l):\n",
        "    final_list = []\n",
        "    n_list = np.arange(l)\n",
        "    np.random.shuffle(n_list)\n",
        "    b_s = int(np.floor(l/s))\n",
        "    #print (b_s)\n",
        "    \n",
        "    for i in range (b_s):\n",
        "        #print (i)\n",
        "        final_list.append(n_list[i*s:(i+1)*s])\n",
        "    return final_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WDDE4MQuKanm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_x,val_x,train_y,val_y = train_test_split(train_data,train_label,test_size=0.2, shuffle=True)\n",
        "\n",
        "l = len(train_x)\n",
        "s= 32\n",
        "\n",
        "for epoch in range (100):\n",
        "\n",
        "  batch_list = shuffle_list(s,l)\n",
        "  for batch in batch_list:\n",
        "    \n",
        "    X = train_x[batch]\n",
        "    Y = train_y[batch]\n",
        "    [loss, accuracy]= model.train_on_batch(X,Y)\n",
        "\n",
        "    print('during training: loss is {} accuracy is {}'.format(loss, accuracy))\n",
        "    print ('prediction')\n",
        "    print (np.argmax(np.squeeze(model.predict(X)),axis=-1))\n",
        "    print ('ground truth')\n",
        "    print (np.argmax(np.squeeze(Y),axis=-1))\n",
        "  model.save(src+'densenet_30_test_2.h5')\n",
        "  print ('epoch', epoch, 'model saved')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "td29GfFwVbFN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}